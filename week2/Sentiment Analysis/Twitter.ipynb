{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e4afa6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/apple/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 records:                                           clean_text  category\n",
      "0  when modi promised ‚Äúminimum government maximum...      -1.0\n",
      "1  talk all the nonsense and continue all the dra...       0.0\n",
      "2  what did just say vote for modi  welcome bjp t...       1.0\n",
      "3  asking his supporters prefix chowkidar their n...       1.0\n",
      "4  answer who among these the most powerful world...       1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "\n",
    "# List files in the dataset directory and pick a supported file\n",
    "supported_exts = [\n",
    "    \".csv\", \".tsv\", \".json\", \".jsonl\", \".xml\", \".parquet\", \".feather\",\n",
    "    \".sqlite\", \".sqlite3\", \".db\", \".db3\", \".s3db\", \".dl3\",\n",
    "    \".xls\", \".xlsx\", \".xlsm\", \".xlsb\", \".odf\", \".ods\", \".odt\"\n",
    "]\n",
    "dataset_files = [f for f in os.listdir(path) if os.path.splitext(f)[1] in supported_exts]\n",
    "\n",
    "if not dataset_files:\n",
    "    raise ValueError(\"No supported dataset files found in the directory.\")\n",
    "\n",
    "file_path = os.path.join(path, dataset_files[0])\n",
    "\n",
    "# Load the latest version\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(\"First 5 records:\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f74ac17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/apple/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Shape: (162980, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised ‚Äúminimum government maximum...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  category\n",
       "0  when modi promised ‚Äúminimum government maximum...      -1.0\n",
       "1  talk all the nonsense and continue all the dra...       0.0\n",
       "2  what did just say vote for modi  welcome bjp t...       1.0\n",
       "3  asking his supporters prefix chowkidar their n...       1.0\n",
       "4  answer who among these the most powerful world...       1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Auto-load dataset\n",
    "supported_exts = [\".csv\", \".tsv\", \".json\", \".jsonl\"]\n",
    "dataset_files = [f for f in os.listdir(path) if os.path.splitext(f)[1] in supported_exts]\n",
    "if not dataset_files:\n",
    "    raise ValueError(\"‚ùå No supported dataset files found in directory.\")\n",
    "file_path = os.path.join(path, dataset_files[0])\n",
    "\n",
    "# Load\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"üìÑ Shape:\", df.shape)\n",
    "df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
